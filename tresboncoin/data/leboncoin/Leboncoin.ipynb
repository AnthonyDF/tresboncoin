{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bf6af68a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import time\n",
    "import random\n",
    "import pandas as pd\n",
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import time\n",
    "import pandas as pd\n",
    "import string\n",
    "from rapidfuzz import process\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b46b216b",
   "metadata": {},
   "outputs": [],
   "source": [
    "lbc1 = pd.read_csv('leboncoin (1).csv')\n",
    "lbc1.columns=['url', '1', '2', '3', '4', 'title', 'price', 'paiement', 'bike_year', 'mileage', 'localisation']\n",
    "lbc2 = pd.read_csv('leboncoin (2).csv')\n",
    "lbc2.columns=['url', '1', '2', '3', '4', 'title', 'price', 'paiement','année', 'bike_year','kilometrage', 'mileage', 'localisation', 'sauvegarder']\n",
    "lbc3 = pd.read_csv('leboncoin (3).csv')\n",
    "lbc3.columns=['url', 'score', 'title', 'price', 'bike_year', 'mileage', 'localisation','1', '2', '3', 'paiement']\n",
    "lbc4 = pd.read_csv('leboncoin (4).csv')\n",
    "lbc4.columns=['url','title', 'price','paiement','bike_year', 'mileage', 'localisation','1', '2', '3', '4']\n",
    "lbc5 = pd.read_csv('leboncoin (5).csv')\n",
    "lbc5.columns=['url','title', 'price','paiement','bike_year', 'mileage', 'localisation','1', '2', '3', '4']\n",
    "lbc6 = pd.read_csv('leboncoin (6).csv')\n",
    "lbc6.columns=['url', '1', '2', '3', '4', 'title', 'price', 'paiement','année', 'bike_year','kilometrage', 'mileage', 'localisation', 'sauvegarder']\n",
    "lbc7 = pd.read_csv('leboncoin (7).csv')\n",
    "lbc7.columns=['url', 'score', 'title', 'price', 'paiement','année', 'bike_year','kilometrage', 'mileage', 'localisation', 'sauvegarder','1', '2', '3']\n",
    "lbc8 = pd.read_csv('leboncoin (8).csv')\n",
    "lbc8.columns=['url', '1', '2', '3', '4', 'title', 'price', 'paiement','année', 'bike_year','kilometrage', 'mileage', 'localisation', 'sauvegarder', '5', '6', '7']\n",
    "lbc9 = pd.read_csv('leboncoin (9).csv')\n",
    "lbc9.columns=['url', '1', '2', '3', '4', 'title', 'price', 'paiement', 'bike_year', 'mileage', 'localisation']\n",
    "lbc10 = pd.read_csv('leboncoin (10).csv')\n",
    "lbc10.columns=['url', '1', '2', '3', '4', '5', 'title', 'type', 'price', 'bike_year', 'mileage', 'localisation','paiement','7']\n",
    "lbc11 = pd.read_csv('leboncoin (11).csv')\n",
    "lbc11.columns=['url', '1', '2', '3', '4', 'title', 'price', 'paiement', 'bike_year', 'mileage', 'localisation']\n",
    "lbc12 = pd.read_csv('leboncoin (12).csv')\n",
    "lbc12.columns=['url', '1', '2', '3', '4', 'title', 'price', 'paiement', 'bike_year', 'mileage', 'localisation']\n",
    "lbc13 = pd.read_csv('leboncoin (13).csv')\n",
    "lbc13.columns=['url', '1', '2', '3', '4', 'title', 'price', 'paiement', 'bike_year', 'mileage', 'localisation']\n",
    "lbc14 = pd.read_csv('leboncoin (14).csv')\n",
    "lbc14.columns=['url','title', 'price', 'paiement', 'bike_year', 'mileage', 'localisation', '1', '2', '3', '4', '5', '6']\n",
    "lbc15 = pd.read_csv('leboncoin (15).csv')\n",
    "lbc15.columns=['url', '1', '2', '3', '4', 'title', 'price', 'paiement', 'bike_year', 'mileage', 'localisation', '5', '6', '7']\n",
    "lbc16 = pd.read_csv('leboncoin (16).csv')\n",
    "lbc16.columns=['url', '1', '2', '3', '4', 'title', 'price', 'paiement', 'bike_year', 'mileage', 'localisation', '5', '6', '7']\n",
    "lbc17 = pd.read_csv('leboncoin (17).csv')\n",
    "lbc17.columns=['url', '1', '2', '3', '4', 'title', 'price', 'paiement', 'bike_year', 'mileage', 'localisation', '5', '6']\n",
    "lbc18 = pd.read_csv('leboncoin (18).csv')\n",
    "lbc18.columns=['url', '1', '2', '3', '4', 'title', 'price', 'bike_year', 'mileage', 'localisation', 'paiement']\n",
    "lbc19 = pd.read_csv('leboncoin (19).csv')\n",
    "lbc19.columns=['url', '1', '2', '3', '4','6', '5', 'title','type', 'price', 'bike_year', 'mileage', 'localisation', 'paiement']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6e0af458",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-6-9f3dd5332ab3>:36: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  history.price = history.price.str.replace('€','').str.replace('\\s','')\n",
      "<ipython-input-6-9f3dd5332ab3>:48: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  history.mileage = history.mileage.str.replace('km','').str.replace('\\s','')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "82.94278407096863\n"
     ]
    }
   ],
   "source": [
    "history = lbc1.append(lbc2)\n",
    "history = history.append(lbc3)\n",
    "history = history.append(lbc4)\n",
    "history = history.append(lbc5)\n",
    "history = history.append(lbc6)\n",
    "history = history.append(lbc7)\n",
    "history = history.append(lbc8)\n",
    "history = history.append(lbc9)\n",
    "history = history.append(lbc10)\n",
    "history = history.append(lbc11)\n",
    "history = history.append(lbc12)\n",
    "history = history.append(lbc13)\n",
    "history = history.append(lbc14)\n",
    "history = history.append(lbc15)\n",
    "history = history.append(lbc16)\n",
    "history = history.append(lbc17)\n",
    "history = history.append(lbc18)\n",
    "\n",
    "\n",
    "history. drop(columns=['1',\n",
    "                        '2',\n",
    "                        '3',\n",
    "                        '4',\n",
    "                        'paiement',\n",
    "                        'année',\n",
    "                        'kilometrage',\n",
    "                        'sauvegarder',\n",
    "                        'score',\n",
    "                        '5',\n",
    "                        '6',\n",
    "                        '7',\n",
    "                        'type'], inplace=True)\n",
    "\n",
    "history.drop_duplicates(subset=['url'], inplace=True)\n",
    "\n",
    "history.price = history.price.str.replace('€','').str.replace('\\s','')\n",
    "\n",
    "def price_cleaning(price):\n",
    "    try:\n",
    "        return int(price)\n",
    "    except:\n",
    "        return np.nan\n",
    "\n",
    "history.price = history.price.apply(price_cleaning)\n",
    "history.dropna(subset=['price'], inplace=True)\n",
    "history= history[history.price > 400]\n",
    "\n",
    "history.mileage = history.mileage.str.replace('km','').str.replace('\\s','')\n",
    "\n",
    "def mileage_cleaning(mileage):\n",
    "    try:\n",
    "        return int(mileage)\n",
    "    except:\n",
    "        return np.nan\n",
    "\n",
    "history.mileage = history.mileage.apply(mileage_cleaning)\n",
    "history.dropna(subset=['mileage'], inplace=True)\n",
    "\n",
    "def year_cleaning(year):\n",
    "    try:\n",
    "        return int(year)\n",
    "    except:\n",
    "        return np.nan\n",
    "\n",
    "history.bike_year = history.bike_year.apply(year_cleaning)\n",
    "history.dropna(subset=['bike_year'], inplace=True)\n",
    "\n",
    "moto_database = pd.read_csv('../master_vehicule_list/bikez.csv')\n",
    "moto_database['brand_model_db'] = moto_database.brand_db + \" \" + moto_database.model_db\n",
    "\n",
    "def remove_punctuations(text):\n",
    "    '''\n",
    "    remove punctuation in a string\n",
    "    '''\n",
    "    for punctuation in string.punctuation:\n",
    "        text = text.replace(punctuation, '')\n",
    "    return text\n",
    "\n",
    "def fuzzy_match_title(new_data, moto_database):\n",
    "\n",
    "    # CLEAN TITLE\n",
    "    new_data = new_data.dropna(subset=['title'])\n",
    "    # lower and remove spaces\n",
    "    new_data.title = new_data.title.str.lower()\n",
    "    # remove punctuation\n",
    "    new_data.title = new_data.title.apply(remove_punctuations)\n",
    "    \n",
    "    # clean title \n",
    "    to_clean = ['carte','grise','restauree','tres','bon','etat','modele', 'historique', 'superbe',\n",
    "                'full', 'neuf', 'option', 'equipé', 'a vendre', 'restauré', 'vends', 'ou', 'échange', \n",
    "                'contre', 'première', 'main', 'tailleux', 'edition',  'top case', 'alarme', 'pr', 'pièces', \n",
    "                'piece', 'pieces', 'cm3', 'scooter', 'moto', 'motos', 'personnalisée', 'permis a2', \n",
    "                'modèle exclusif', 'équipé piste', 'piste', 'équipé', 'nardo', 'gris', 'blanc', 'noir', 'jaune', \n",
    "                'rouge', 'nardo', 'bleu', 'bleue', 'vert', 'orange','équipe ok rte', 'racing', 'km', ' cm ', 'café racer']\n",
    "    for word in to_clean:\n",
    "        new_data.title = new_data.title.str.replace(word, '').str.replace('  ', ' ')\n",
    "        \n",
    "    new_data.title = new_data.title.str.replace('20\\d{2}','', regex=True)\n",
    "    new_data.title = new_data.title.str.replace('19\\d{2}','', regex=True)\n",
    "        \n",
    "    def extract_brand(title):\n",
    "        brand_list = moto_database['brand_db'].unique().tolist()\n",
    "        for brand in brand_list:\n",
    "            if brand in title:\n",
    "                return brand\n",
    "        \n",
    "    new_data['brand'] = new_data.title.apply(extract_brand)\n",
    "    new_data = new_data.dropna(subset=['brand'])\n",
    "    \n",
    "    \n",
    "    def clean_title(title, brand):\n",
    "        return title.replace(brand, '').replace('  ',' ')\n",
    "        \n",
    "    new_data.title = new_data.apply(lambda x: clean_title(x['title'], x['brand']), axis=1)\n",
    "\n",
    "    # MATCH TITLE\n",
    "    def choices(year, brand, type_name):\n",
    "        choices = moto_database[(moto_database.brand_db==brand) & (moto_database.year_db == year)][type_name].unique().tolist()\n",
    "        return [str(x) for  x in choices]\n",
    "    \n",
    "    # unpack results\n",
    "    def unpack_tuple_name(result):\n",
    "        try:\n",
    "            return result[0]\n",
    "        except:\n",
    "            return np.nan\n",
    "\n",
    "    def unpack_tuple_score(result):\n",
    "        try:\n",
    "            return result[1]\n",
    "        except:\n",
    "            return np.nan\n",
    "        \n",
    "    def match_title(choices, to_match):\n",
    "        return process.extractOne(to_match, choices)\n",
    "\n",
    "    new_data['fuzzy_match']= new_data.apply(lambda x: match_title(choices(x['bike_year'], x['brand'], 'model_submodel_db'), x['title']), axis=1)\n",
    "    \n",
    "    new_data['fuzzy_score'] = new_data['fuzzy_match'].apply(unpack_tuple_score)\n",
    "    new_data['fuzzy_brand_model'] = new_data['fuzzy_match'].apply(unpack_tuple_name)\n",
    "    new_data.drop(columns=['fuzzy_match'], inplace=True)\n",
    "    \n",
    "    return new_data\n",
    "\n",
    "startTime = time.time()\n",
    "\n",
    "history_matched = fuzzy_match_title(history, moto_database)\n",
    "\n",
    "endTime = time.time()\n",
    "print(endTime-startTime)\n",
    "\n",
    "history_matched = history_matched[history_matched.fuzzy_score>75]\n",
    "\n",
    "history_matched = history_matched.merge(moto_database, how='inner', left_on=['brand', 'bike_year', 'fuzzy_brand_model'], right_on=['brand_db', 'year_db', 'model_submodel_db'])\n",
    "\n",
    "history_matched.drop(columns=['fuzzy_score','brand_db', 'model_db',\n",
    "       'model_inv_db', 'model_submodel_db', 'model_submodel_inv_db', 'year_db',\n",
    "       'category_db', 'engine_type_db', 'power_db',\n",
    "       'torque_db', 'compression_db', 'cooling_system_db', 'dry_weight_db',\n",
    "       'power/weight_ratio_db', 'model_size_db', 'model_size_inv_db',\n",
    "       'brand_model_db'], inplace= True)\n",
    "history_matched\n",
    "\n",
    "history_matched.rename(columns={'fuzzy_brand_model':'model' ,'engine_size_db':'engine_size'}, inplace=True)\n",
    "\n",
    "history_matched.to_csv('leboncoin.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9326176b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9261, 9)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history_matched.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
