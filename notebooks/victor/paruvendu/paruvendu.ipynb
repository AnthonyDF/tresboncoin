{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import datetime\n",
    "import re\n",
    "import time\n",
    "import os\n",
    "import json\n",
    "from PIL import Image \n",
    "import PIL \n",
    "pd.set_option('display.max_columns', None)\n",
    "import random\n",
    "import codecs\n",
    "import subprocess"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Headers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "headers = {\n",
    "    'authority': 'www.paruvendu.fr',\n",
    "    'cache-control': 'max-age=0',\n",
    "    'sec-ch-ua': '\" Not A;Brand\";v=\"99\", \"Chromium\";v=\"90\", \"Google Chrome\";v=\"90\"',\n",
    "    'sec-ch-ua-mobile': '?0',\n",
    "    'upgrade-insecure-requests': '1',\n",
    "    'user-agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/90.0.4430.212 Safari/537.36',\n",
    "    'accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,image/apng,*/*;q=0.8,application/signed-exchange;v=b3;q=0.9',\n",
    "    'sec-fetch-site': 'none',\n",
    "    'sec-fetch-mode': 'navigate',\n",
    "    'sec-fetch-user': '?1',\n",
    "    'sec-fetch-dest': 'document',\n",
    "    'accept-language': 'fr-FR,fr;q=0.9,en-US;q=0.8,en;q=0.7'\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save pages x15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_page_list(req, page=1):\n",
    "    datetime_1 = datetime.datetime.now().strftime(\"%Y-%m-%d_%Hh%M\")\n",
    "    page_list_name = \"paruvendu\" + \"-\" + datetime_1 + \"-\" + str(page)\n",
    "    with open(\"pages/\" + page_list_name + \".html\", \"w\")  as file:\n",
    "        file.write(req.text)\n",
    "        file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 2])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pages = np.arange(1, 3)\n",
    "pages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x15 saved: 1\n",
      "x15 saved: 2\n"
     ]
    }
   ],
   "source": [
    "for page_ in pages:\n",
    "    req_x15 = requests.get(f\"https://www.paruvendu.fr/auto-moto/listefo/default/default?moto-typeRech=&r=VMOMO000&px1=ex:%2050000&r2=&codeINSEE=&lo=&pa=&ray=100&cy=&nrj=&km1=&a0=&fulltext=&p={page_}\",\n",
    "                           headers = headers)\n",
    "    save_page_list(req_x15, page=page_)\n",
    "    time.sleep(random.randint(4, 5))\n",
    "    print(\"x15 saved: \" + str(page_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract data from saved x15"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'paruvendu-2021-06-02_21h20-30.html'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_test_name = [file for file in os.listdir(\"pages\") if file.endswith(\"html\")][1]\n",
    "file_test_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'pages/paruvendu-2021-06-02_21h20-30.html'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_check_x15_good = f\"pages/{file_test_name}\"\n",
    "file_check_x15_good"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get prices from saved x15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_prices_from_saved_x15(r):\n",
    "    \n",
    "    # set empty price list\n",
    "    price_list = []\n",
    "    \n",
    "    # get soup\n",
    "    soup = BeautifulSoup(r, 'html.parser')\n",
    "    \n",
    "    # extract price\n",
    "    step1 = soup.select('div[class*=\"lazyload_bloc\"]')\n",
    "    if len(step1)>0:\n",
    "        for k in step1:\n",
    "            step2 = k.find_all(\"div\", class_=\"ergov3-priceannonce\")\n",
    "            if len(step2)>0:\n",
    "                step3 = re.findall('[0-9]', step2[0].text)\n",
    "                if len(step3)>0:\n",
    "                    price = float(\"\".join(step3))\n",
    "                    price_list.append(price)\n",
    "                else:\n",
    "                    price_list.append(np.nan)\n",
    "            else:\n",
    "                return None\n",
    "    else:\n",
    "        return None\n",
    "                    \n",
    "    return price_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[5000.0,\n",
       " 6200.0,\n",
       " 3200.0,\n",
       " 17500.0,\n",
       " 3790.0,\n",
       " 2000.0,\n",
       " 4500.0,\n",
       " 4500.0,\n",
       " 13500.0,\n",
       " 3500.0,\n",
       " 16500.0,\n",
       " 6499.0,\n",
       " 6200.0,\n",
       " 8500.0,\n",
       " 10250.0]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(file_check_x15_good, 'r') as f:\n",
    "    readable_html = f.read()\n",
    "    prices = get_prices_from_saved_x15(readable_html)\n",
    "prices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get references from saved x15"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "for this website there is no Reference on page x15 but we can still find a unique ID that will differ from announce reference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_unique_ID_from_saved_x15(r):\n",
    "    \n",
    "    # set empty uniq_ID list\n",
    "    uniq_ID_list = []\n",
    "    \n",
    "    # get soup\n",
    "    soup = BeautifulSoup(r, 'html.parser')\n",
    "    \n",
    "    # extract uniq ID\n",
    "    step1 = soup.select('div[class*=\"lazyload_bloc\"]')\n",
    "    if len(step1)>0:\n",
    "        for k in step1:\n",
    "            if \"data-id\" in k.attrs:\n",
    "                uniq_ID_list.append(k.attrs[\"data-id\"])\n",
    "            else:\n",
    "                uniq_ID_list.append(np.nan)\n",
    "    else:\n",
    "        return None\n",
    "    \n",
    "    return uniq_ID_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1253979582',\n",
       " '1253978698',\n",
       " '1253977270',\n",
       " '1253977145',\n",
       " '1253976914',\n",
       " '1253889260',\n",
       " '1253917685',\n",
       " '1253962187',\n",
       " '1253870175',\n",
       " '1253973918',\n",
       " '1253971839',\n",
       " '1246648333',\n",
       " '1253894110',\n",
       " '1253963695',\n",
       " '1250913038']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(file_check_x15_good, 'r') as f:\n",
    "    readable_html = f.read()\n",
    "    unique_id = get_unique_ID_from_saved_x15(readable_html)\n",
    "unique_id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get urls from saved x15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_urls_from_saved_x15(r):\n",
    "    \n",
    "    # set empty url list\n",
    "    url_list = []\n",
    "    \n",
    "    # get soup\n",
    "    soup = BeautifulSoup(r, 'html.parser')\n",
    "    \n",
    "    # extract url\n",
    "    step1 = soup.select('div[class*=\"lazyload_bloc\"]')\n",
    "    if len(step1)>0:\n",
    "        for k in step1:\n",
    "            step2 = k.find_all(\"a\")\n",
    "            if len(step2)>2:\n",
    "                if \"href\" in step2[1].attrs:\n",
    "                    url_list.append(step2[1].attrs[\"href\"])\n",
    "                else:\n",
    "                    url_list.append(np.nan)\n",
    "            else:\n",
    "                return None\n",
    "    else:\n",
    "        return None\n",
    "    \n",
    "    return url_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['https://www.paruvendu.fr/a/moto-scooter/moto/bmw/1200-cm3/1253979582A1KVMOMOBM',\n",
       " 'https://www.paruvendu.fr/a/moto-scooter/moto/yamaha/689-cm3/1253978698A1KVMOMOYA',\n",
       " 'https://www.paruvendu.fr/a/moto-scooter/moto/suzuki/650-cm3/1253977270A1KVMOMOSU',\n",
       " 'https://www.paruvendu.fr/a/moto-scooter/moto/harley-davidson/1680-cm3/1253977145A1KVMOMOHD',\n",
       " 'https://www.paruvendu.fr/a/moto-scooter/moto/yamaha/900-cm3/1253976914A1KVMOMOYA',\n",
       " 'https://www.paruvendu.fr/a/moto-scooter/moto/kawasaki/1000-cm3/1253889260A1KVMOMOKA',\n",
       " 'https://www.paruvendu.fr/a/moto-scooter/moto/royal-enfield/535-cm3/1253917685A1KVMOMORE',\n",
       " 'https://www.paruvendu.fr/a/moto-scooter/moto/yamaha/1300-cm3/1253962187A1KVMOMOYA',\n",
       " 'https://www.paruvendu.fr/a/moto-scooter/moto/harley-davidson/1690-cm3/1253870175A1KVMOMOHD',\n",
       " 'https://www.paruvendu.fr/a/moto-scooter/moto/honda/900-cm3/1253973918A1KVMOMOHO',\n",
       " 'https://www.paruvendu.fr/a/moto-scooter/moto/harley-davidson/1690-cm3/1253971839A1KVMOMOHD',\n",
       " 'https://www.paruvendu.fr/a/moto-scooter/moto/triumph/900-cm3/1246648333A1KVMOMOTR',\n",
       " 'https://www.paruvendu.fr/a/moto-scooter/moto/kawasaki/1043-cm3/1253894110A1KVMOMOKA',\n",
       " 'https://www.paruvendu.fr/a/moto-scooter/moto/suzuki/1800-cm3/1253963695A1KVMOMOSU',\n",
       " 'https://www.paruvendu.fr/a/moto-scooter/moto/ducati/1198-cm3/1250913038A1KVMOMODU']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(file_check_x15_good, 'r') as f:\n",
    "    readable_html = f.read()\n",
    "    urls_list = get_urls_from_saved_x15(readable_html)\n",
    "urls_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get title from saved x15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_titles_from_saved_x15(r):\n",
    "    \n",
    "    # set empty title list\n",
    "    title_list = []\n",
    "    \n",
    "    # get soup\n",
    "    soup = BeautifulSoup(r, 'html.parser')\n",
    "    \n",
    "    # extract title\n",
    "    step1 = soup.select('div[class*=\"lazyload_bloc\"]')\n",
    "    if len(step1)>0:\n",
    "        for k in step1:\n",
    "            step2 = k.find_all(\"h3\")\n",
    "            if len(step2)>0:\n",
    "                title_list.append(step2[0].text.replace(\"\\n\", \"\").replace(\"\\t\", \"\").replace(\"Moto \", \"\").strip())\n",
    "            else:\n",
    "                title_list.append(np.nan)\n",
    "    else:\n",
    "        return None\n",
    "    #\n",
    "    return title_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['BMW',\n",
       " 'YAMAHA',\n",
       " 'SUZUKI',\n",
       " 'HARLEY-DAVIDSON',\n",
       " 'YAMAHA',\n",
       " 'KAWASAKI',\n",
       " 'ROYAL ENFIELD',\n",
       " 'YAMAHA',\n",
       " 'HARLEY-DAVIDSON',\n",
       " 'HONDA',\n",
       " 'HARLEY-DAVIDSON',\n",
       " 'TRIUMPH',\n",
       " 'KAWASAKI',\n",
       " 'SUZUKI',\n",
       " 'DUCATI 1198 s']"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(file_check_x15_good, 'r') as f:\n",
    "    readable_html = f.read()\n",
    "    title_list = get_titles_from_saved_x15(readable_html)\n",
    "title_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## temp df template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>url</th>\n",
       "      <th>unique id</th>\n",
       "      <th>price</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   url  unique id  price  title\n",
       "0  NaN        NaN    NaN    NaN"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp_template = pd.DataFrame({\"url\": [np.nan],\n",
    "                              \"unique id\": [np.nan],\n",
    "                              \"price\": [np.nan],\n",
    "                              \"title\": [np.nan]\n",
    "                            })\n",
    "temp_template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_temporary_data(url_, uniq_id_, price_, title_):\n",
    "\n",
    "    # load csv if exists or starting from template\n",
    "    data_paruvendu = \"../../../tresboncoin/data/paruvendu_ad.csv\"\n",
    "    #\n",
    "    if os.path.isfile(data_paruvendu) is False:\n",
    "        df = temp_template.copy()\n",
    "    else:\n",
    "        data = pd.read_csv(data_paruvendu)\n",
    "        df = temp_template.copy()\n",
    "        \n",
    "    # adding data\n",
    "    df[\"url\"] = url_\n",
    "    df[\"unique id\"] = uniq_id_\n",
    "    df[\"price\"] = price_\n",
    "    df[\"title\"] = title_\n",
    "    \n",
    "    # concatenate to csv and write\n",
    "    try:\n",
    "        data = pd.concat([data, df], axis=0)\n",
    "        data.to_csv(path_or_buf = data_paruvendu, index=False)\n",
    "    except:\n",
    "        df.to_csv(path_or_buf = data_paruvendu, index=False)\n",
    "        \n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Download single announce pages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### check if an announce with different price but same unique id exists in dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_paruvendu = \"../../../tresboncoin/data/paruvendu.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_price = pd.read_csv(data_paruvendu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1283, 20)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_price.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_the_announce(df, uniq_id, price):\n",
    "    if int(uniq_id) in list(df[\"unique id\"]):\n",
    "        index_ = df.index[df['unique id'] == int(uniq_id)].tolist()[0]\n",
    "        \n",
    "        # if an announce with same uniq id and same price is found, return true and skip\n",
    "        return df.iloc[index_][\"price\"]!=price\n",
    "    \n",
    "    # else, return false and add the announce\n",
    "    return True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### save annonce function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_page_uniq(req, uniq_id):\n",
    "    datetime_1 = datetime.datetime.now().strftime(\"%Y-%m-%d_%Hh%M\")\n",
    "    page_name = \"paruvendu\" + \"-\" + uniq_id + \"-\" + datetime_1\n",
    "    with open(\"annonces/\" + page_name + \".html\", \"w\")  as file:\n",
    "        file.write(req.text)\n",
    "        file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### check if id exists or price changed and save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "page_count = 1\n",
    "for html_file in [file for file in os.listdir(\"pages\") if file.endswith(\"html\")]:\n",
    "    with open(f\"pages/{html_file}\", 'r') as f:\n",
    "        readable_html = f.read()\n",
    "        urls_list = get_urls_from_saved_x15(readable_html)\n",
    "        unique_id = get_unique_ID_from_saved_x15(readable_html)\n",
    "        prices_list = get_prices_from_saved_x15(readable_html)\n",
    "    if urls_list != None:\n",
    "        for url_single, uniq_id, price_ in zip(urls_list, unique_id, prices_list):\n",
    "            if add_the_announce(data_price, uniq_id, price_):\n",
    "                req_uniq = requests.get(url_single, headers = headers)\n",
    "                save_page_uniq(req_uniq, uniq_id)\n",
    "                print(str(page_count) + \". saved page id: \" + uniq_id)\n",
    "                time.sleep(1)\n",
    "                page_count += 1\n",
    "            else:\n",
    "                print(\"NO! \" + url_single)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1253977270 in list(data_price[\"unique id\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://www.paruvendu.fr/a/moto-scooter/moto/honda/600-cm3/1254313672A1KVMOMOHO'"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_price.iloc[1158][\"url\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Process single announces\n",
    "Saving scaled images x3 and adding announce to DataFrame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DataFrame template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>url</th>\n",
       "      <th>reference</th>\n",
       "      <th>unique id</th>\n",
       "      <th>date_scrapped</th>\n",
       "      <th>announce_publication_date</th>\n",
       "      <th>vehicle brand</th>\n",
       "      <th>vehicle type</th>\n",
       "      <th>moto scoot</th>\n",
       "      <th>color</th>\n",
       "      <th>vehicle condition</th>\n",
       "      <th>price</th>\n",
       "      <th>city</th>\n",
       "      <th>postal code</th>\n",
       "      <th>vehicle release date</th>\n",
       "      <th>mileage</th>\n",
       "      <th>Fiscal power [HP]</th>\n",
       "      <th>engine capacity [CC]</th>\n",
       "      <th>comments</th>\n",
       "      <th>seller</th>\n",
       "      <th>seller_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   url  reference  unique id  date_scrapped  announce_publication_date  \\\n",
       "0  NaN        NaN        NaN            NaN                        NaN   \n",
       "\n",
       "   vehicle brand  vehicle type  moto scoot  color  vehicle condition  price  \\\n",
       "0            NaN           NaN         NaN    NaN                NaN    NaN   \n",
       "\n",
       "   city  postal code  vehicle release date  mileage  Fiscal power [HP]  \\\n",
       "0   NaN          NaN                   NaN      NaN                NaN   \n",
       "\n",
       "   engine capacity [CC]  comments  seller  seller_name  \n",
       "0                   NaN       NaN     NaN          NaN  "
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "announce_template = pd.DataFrame({\"url\": [np.nan],\n",
    "                                  \"reference\": [np.nan],\n",
    "                                  \"unique id\": [np.nan],\n",
    "                                  \"date_scrapped\": [np.nan],\n",
    "                                  \"announce_publication_date\": [np.nan],\n",
    "                                  \"vehicle brand\": [np.nan],\n",
    "                                  \"vehicle type\": [np.nan],\n",
    "                                  \"moto scoot\": [np.nan],\n",
    "                                  \"color\": [np.nan],\n",
    "                                  \"vehicle condition\": [np.nan],\n",
    "                                  \"price\": [np.nan],\n",
    "                                  \"city\": [np.nan],\n",
    "                                  \"postal code\": [np.nan],\n",
    "                                  \"vehicle release date\": [np.nan],\n",
    "                                  \"mileage\": [np.nan],\n",
    "                                  \"Fiscal power [HP]\": [np.nan],\n",
    "                                  \"engine capacity [CC]\": [np.nan],\n",
    "                                  \"comments\": [np.nan],\n",
    "                                  \"seller\": [np.nan],\n",
    "                                  \"seller_name\": [np.nan]})\n",
    "announce_template"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## test announce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_check_name_single = \"paruvendu-1248033282-2021-05-30_19h04\"\n",
    "#\n",
    "file_check_single = f\"annonces/{file_check_name_single}.html\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_url(r):\n",
    "    \n",
    "    # set empty url list\n",
    "    url_ = \"\"\n",
    "    \n",
    "    # get soup\n",
    "    soup = BeautifulSoup(r, 'html.parser')\n",
    "    \n",
    "    # extract url\n",
    "    step1 = soup.select('meta[property*=\"og:url\"]')\n",
    "    if len(step1)>0:\n",
    "        return step1[0].attrs[\"content\"].split(\"?\")[0]\n",
    "    else:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'pages/paruvendu-1248033282-2021-05-30_19h04.html'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-82-84c6d3a4d409>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_check_single\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'r'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0mreadable_html\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mg_url\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_url\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreadable_html\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mg_url\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'pages/paruvendu-1248033282-2021-05-30_19h04.html'"
     ]
    }
   ],
   "source": [
    "with open(file_check_single, 'r') as f:\n",
    "    readable_html = f.read()\n",
    "    g_url = get_url(readable_html)\n",
    "g_url"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get reference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_reference(r):\n",
    "    \n",
    "    # set empty reference list\n",
    "    ref_ = \"\"\n",
    "    \n",
    "    # get soup\n",
    "    soup = BeautifulSoup(r, 'html.parser')\n",
    "    \n",
    "    # extract ref\n",
    "    step1 = soup.select('div[class*=\"vvdetails14_refdate\"]')\n",
    "    if len(step1)>0:\n",
    "        return step1[0].text.replace(\"\\n\", \"\").replace(\"\\t\", \"\").split(\"ParuVendu\")[-1].split(\"-\")[0].strip()\n",
    "    else:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'pages/paruvendu-1248033282-2021-05-30_19h04.html'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-84-6ddfb4fb025c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_check_single\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'r'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0mreadable_html\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mg_ref\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_reference\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreadable_html\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mg_ref\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'pages/paruvendu-1248033282-2021-05-30_19h04.html'"
     ]
    }
   ],
   "source": [
    "with open(file_check_single, 'r') as f:\n",
    "    readable_html = f.read()\n",
    "    g_ref = get_reference(readable_html)\n",
    "g_ref"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get unique ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_uniq_id(url_):\n",
    "    return url_.split(\"/\")[-1].split(\"A1\")[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'pages/paruvendu-1248033282-2021-05-30_19h04.html'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-86-f8c9270e3ed9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_check_single\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'r'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0mreadable_html\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mg_url\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_url\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreadable_html\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mget_uniq_id\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mg_url\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'pages/paruvendu-1248033282-2021-05-30_19h04.html'"
     ]
    }
   ],
   "source": [
    "with open(file_check_single, 'r') as f:\n",
    "    readable_html = f.read()\n",
    "    g_url = get_url(readable_html)\n",
    "get_uniq_id(g_url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### get publication date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_publication_date(r):\n",
    "    \n",
    "    # set empty \n",
    "    pub_ = \"\"\n",
    "    \n",
    "    # get soup\n",
    "    soup = BeautifulSoup(r, 'html.parser')\n",
    "    \n",
    "    # extract\n",
    "    step1 = soup.select('div[class*=\"vvdetails14_refdate\"]')\n",
    "    if len(step1)>0:\n",
    "        try:\n",
    "            return step1[0].text.replace(\"\\n\", \"\").replace(\"\\t\", \"\").split(\"ParuVendu\")[-1].split(\"-\")[1].strip().split(\" \")[1]\n",
    "        except:\n",
    "            return np.nan\n",
    "    else:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'pages/paruvendu-1248033282-2021-05-30_19h04.html'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-88-ea7207a6d3c6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_check_single\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'r'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0mreadable_html\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mg_pub\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_publication_date\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreadable_html\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mg_pub\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'pages/paruvendu-1248033282-2021-05-30_19h04.html'"
     ]
    }
   ],
   "source": [
    "with open(file_check_single, 'r') as f:\n",
    "    readable_html = f.read()\n",
    "    g_pub = get_publication_date(readable_html)\n",
    "g_pub"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get vehicule brand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_brand(r):\n",
    "    \n",
    "    # set empty \n",
    "    brand_ = \"\"\n",
    "    \n",
    "    # get soup\n",
    "    soup = BeautifulSoup(r, 'html.parser')\n",
    "    \n",
    "    # extract\n",
    "    step1 = soup.select('div[id*=\"blcheader\"]')\n",
    "    if len(step1)>0:\n",
    "        return step1[0].select(\"h1\")[0].text.replace(u'\\xa0', u' ').strip().split(\" \")[-1]\n",
    "    else:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'pages/paruvendu-1248033282-2021-05-30_19h04.html'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-90-4f2d2d813115>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_check_single\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'r'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0mreadable_html\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mg_brand\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_brand\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreadable_html\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mg_brand\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'pages/paruvendu-1248033282-2021-05-30_19h04.html'"
     ]
    }
   ],
   "source": [
    "with open(file_check_single, 'r') as f:\n",
    "    readable_html = f.read()\n",
    "    g_brand = get_brand(readable_html)\n",
    "g_brand"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get vehicule type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_type(r):\n",
    "    \n",
    "    # get soup\n",
    "    soup = BeautifulSoup(r, 'html.parser')\n",
    "    \n",
    "    # extract\n",
    "    step1 = soup.select('div[class*=\"im12_txt_ann\"]')\n",
    "    if len(step1)>0:\n",
    "        step2 = step1[0].select('li[class*=\"nologo\"]')\n",
    "        if len(step2)>0:\n",
    "            step3 = step2[0].select(\"span\")\n",
    "            if len(step3)>0:\n",
    "                return step3[0].text.replace(\"\\n\", \"\")\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'pages/paruvendu-1248033282-2021-05-30_19h04.html'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-92-f19323cd4028>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_check_single\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'r'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0mreadable_html\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mg_type\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreadable_html\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mg_type\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'pages/paruvendu-1248033282-2021-05-30_19h04.html'"
     ]
    }
   ],
   "source": [
    "with open(file_check_single, 'r') as f:\n",
    "    readable_html = f.read()\n",
    "    g_type = get_type(readable_html)\n",
    "g_type"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### get moto scoot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_moto(r):\n",
    "        \n",
    "    # get soup\n",
    "    soup = BeautifulSoup(r, 'html.parser')\n",
    "    \n",
    "    # extract\n",
    "    step1 = soup.select('div[id*=\"blcheader\"]')\n",
    "    if len(step1)>0:\n",
    "        return step1[0].select(\"h1\")[0].text.replace(u'\\xa0', u' ').strip().split(\" \")[0]\n",
    "    else:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'pages/paruvendu-1248033282-2021-05-30_19h04.html'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-94-c4234a1fcdbd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_check_single\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'r'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0mreadable_html\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mg_moto\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_moto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreadable_html\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mg_moto\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'pages/paruvendu-1248033282-2021-05-30_19h04.html'"
     ]
    }
   ],
   "source": [
    "with open(file_check_single, 'r') as f:\n",
    "    readable_html = f.read()\n",
    "    g_moto = get_moto(readable_html)\n",
    "g_moto"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### get color"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_color(r):\n",
    "    \n",
    "    # get soup\n",
    "    soup = BeautifulSoup(r, 'html.parser')\n",
    "    \n",
    "    # extract\n",
    "    step1 = soup.select('div[class*=\"im12_txt_ann\"]')\n",
    "    if len(step1)>0:\n",
    "        step2 = step1[0].select('li[class*=\"puiss\"]')\n",
    "        if len(step2)>0:\n",
    "            for k in step2:\n",
    "                if k.text.find(\"Couleur\")>0:\n",
    "                    return k.select(\"span\")[0].text.strip()\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'pages/paruvendu-1248033282-2021-05-30_19h04.html'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-96-498ba2752d80>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_check_single\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'r'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0mreadable_html\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mg_color\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_color\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreadable_html\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mg_color\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'pages/paruvendu-1248033282-2021-05-30_19h04.html'"
     ]
    }
   ],
   "source": [
    "with open(file_check_single, 'r') as f:\n",
    "    readable_html = f.read()\n",
    "    g_color = get_color(readable_html)\n",
    "g_color"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### get vehicle condition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cond(r):\n",
    "    \n",
    "    # get soup\n",
    "    soup = BeautifulSoup(r, 'html.parser')\n",
    "    \n",
    "    # extract\n",
    "    step1 = soup.select('div[class*=\"im12_txt_ann\"]')\n",
    "    if len(step1)>0:\n",
    "        step2 = step1[0].select('li[class*=\"puiss\"]')\n",
    "        if len(step2)>0:\n",
    "            for k in step2:\n",
    "                if k.text.find(\"Etat\")>0:\n",
    "                    return k.select(\"span\")[0].text.strip()\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'pages/paruvendu-1248033282-2021-05-30_19h04.html'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-98-b544054533d4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_check_single\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'r'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0mreadable_html\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mg_cond\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_cond\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreadable_html\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mg_cond\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'pages/paruvendu-1248033282-2021-05-30_19h04.html'"
     ]
    }
   ],
   "source": [
    "with open(file_check_single, 'r') as f:\n",
    "    readable_html = f.read()\n",
    "    g_cond = get_cond(readable_html)\n",
    "g_cond"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### get fiscal power"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_power(r):\n",
    "    \n",
    "    # get soup\n",
    "    soup = BeautifulSoup(r, 'html.parser')\n",
    "    \n",
    "    # extract\n",
    "    step1 = soup.select('div[class*=\"im12_txt_ann\"]')\n",
    "    if len(step1)>0:\n",
    "        step2 = step1[0].select('li[class*=\"puiss\"]')\n",
    "        if len(step2)>0:\n",
    "            for k in step2:\n",
    "                if k.text.find(\"fiscale\")>0:\n",
    "                    return int(k.select(\"span\")[0].text.strip())\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'pages/paruvendu-1248033282-2021-05-30_19h04.html'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-100-cfe0c25e90e2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_check_single\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'r'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0mreadable_html\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mg_power\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_power\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreadable_html\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mg_power\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'pages/paruvendu-1248033282-2021-05-30_19h04.html'"
     ]
    }
   ],
   "source": [
    "with open(file_check_single, 'r') as f:\n",
    "    readable_html = f.read()\n",
    "    g_power = get_power(readable_html)\n",
    "g_power"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### get price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_price(r):\n",
    "    \n",
    "    # get soup\n",
    "    soup = BeautifulSoup(r, 'html.parser')\n",
    "    \n",
    "    # extract\n",
    "    step1 = soup.select('div[id*=\"autoprix\"]')\n",
    "    if len(step1)>0:\n",
    "        try:\n",
    "            return float(\"\".join(re.findall(\"[0-9]\", step1[0].text)))\n",
    "        except:\n",
    "            return np.nan\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'pages/paruvendu-1248033282-2021-05-30_19h04.html'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-102-be78b0b9ff38>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_check_single\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'r'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0mreadable_html\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mg_price\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_price\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreadable_html\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mg_price\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'pages/paruvendu-1248033282-2021-05-30_19h04.html'"
     ]
    }
   ],
   "source": [
    "with open(file_check_single, 'r') as f:\n",
    "    readable_html = f.read()\n",
    "    g_price = get_price(readable_html)\n",
    "g_price"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### get city"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_city(r):\n",
    "    \n",
    "    # get soup\n",
    "    soup = BeautifulSoup(r, 'html.parser')\n",
    "    \n",
    "    # extract\n",
    "    step1 = soup.select('div[id*=\"blcheader\"]')\n",
    "    if len(step1)>0:\n",
    "        return step1[0].select(\"h2\")[0].text.split(\" \")[-1].replace(\"\\n\", \"\")\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'pages/paruvendu-1248033282-2021-05-30_19h04.html'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-104-5b3df0d0ef7b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_check_single\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'r'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0mreadable_html\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mg_city\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_city\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreadable_html\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mg_city\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'pages/paruvendu-1248033282-2021-05-30_19h04.html'"
     ]
    }
   ],
   "source": [
    "with open(file_check_single, 'r') as f:\n",
    "    readable_html = f.read()\n",
    "    g_city = get_city(readable_html)\n",
    "g_city"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### get postal code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_postalcode(r):\n",
    "    \n",
    "    # get soup\n",
    "    soup = BeautifulSoup(r, 'html.parser')\n",
    "    \n",
    "    # extract\n",
    "    step1 = soup.select('div[id*=\"blcheader\"]')\n",
    "    if len(step1)>0:\n",
    "        return step1[0].select(\"h2\")[0].text.split(\" \")[0].replace(\"\\n\", \"\")\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'pages/paruvendu-1248033282-2021-05-30_19h04.html'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-106-4734ef0dd7b7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_check_single\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'r'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0mreadable_html\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mg_post\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_postalcode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreadable_html\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mg_post\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'pages/paruvendu-1248033282-2021-05-30_19h04.html'"
     ]
    }
   ],
   "source": [
    "with open(file_check_single, 'r') as f:\n",
    "    readable_html = f.read()\n",
    "    g_post = get_postalcode(readable_html)\n",
    "g_post"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### get vehicle release date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_releasedate(r):\n",
    "    \n",
    "    # get soup\n",
    "    soup = BeautifulSoup(r, 'html.parser')\n",
    "    \n",
    "    # extract\n",
    "    step1 = soup.select('div[class*=\"im12_txt_ann\"]')\n",
    "    if len(step1)>0:\n",
    "        step2 = step1[0].select('li[class*=\"ann\"]')\n",
    "        if len(step2)>0:\n",
    "            step3 = step2[0].select(\"span\")\n",
    "            if len(step3)>0:\n",
    "                return \"\".join(re.findall(\"[0-9]\", step3[0].text))\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'pages/paruvendu-1248033282-2021-05-30_19h04.html'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-108-f8943448c6e5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_check_single\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'r'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0mreadable_html\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mg_release\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_releasedate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreadable_html\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mg_release\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'pages/paruvendu-1248033282-2021-05-30_19h04.html'"
     ]
    }
   ],
   "source": [
    "with open(file_check_single, 'r') as f:\n",
    "    readable_html = f.read()\n",
    "    g_release = get_releasedate(readable_html)\n",
    "g_release"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### get vehicle mileage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mileage(r):\n",
    "    \n",
    "    # get soup\n",
    "    soup = BeautifulSoup(r, 'html.parser')\n",
    "    \n",
    "    # extract\n",
    "    step1 = soup.select('div[class*=\"im12_txt_ann\"]')\n",
    "    if len(step1)>0:\n",
    "        step2 = step1[0].select('li[class*=\"kil\"]')\n",
    "        if len(step2)>0:\n",
    "            step3 = step2[0].select(\"span\")\n",
    "            if len(step3)>0:\n",
    "                return \"\".join(re.findall(\"[0-9]\", step3[0].text))\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'pages/paruvendu-1248033282-2021-05-30_19h04.html'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-110-03286abbd47b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_check_single\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'r'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0mreadable_html\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mg_mileage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_mileage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreadable_html\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mg_mileage\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'pages/paruvendu-1248033282-2021-05-30_19h04.html'"
     ]
    }
   ],
   "source": [
    "with open(file_check_single, 'r') as f:\n",
    "    readable_html = f.read()\n",
    "    g_mileage = get_mileage(readable_html)\n",
    "g_mileage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### get engine capacity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_capa(r):\n",
    "    \n",
    "    # get soup\n",
    "    soup = BeautifulSoup(r, 'html.parser')\n",
    "    \n",
    "    # extract\n",
    "    step1 = soup.select('div[class*=\"im12_txt_ann\"]')\n",
    "    if len(step1)>0:\n",
    "        step2 = step1[0].select('li[class*=\"cyl\"]')\n",
    "        if len(step2)>0:\n",
    "            step3 = step2[0].select(\"span\")\n",
    "            if len(step3)>0:\n",
    "                return \"\".join(re.findall(\"[0-9]\", step3[0].text))\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'pages/paruvendu-1248033282-2021-05-30_19h04.html'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-112-13c3d69b0a6d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_check_single\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'r'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0mreadable_html\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mg_capa\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_capa\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreadable_html\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mg_capa\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'pages/paruvendu-1248033282-2021-05-30_19h04.html'"
     ]
    }
   ],
   "source": [
    "with open(file_check_single, 'r') as f:\n",
    "    readable_html = f.read()\n",
    "    g_capa = get_capa(readable_html)\n",
    "g_capa"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### get comment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_comment(r):\n",
    "    \n",
    "    # get soup\n",
    "    soup = BeautifulSoup(r, 'html.parser')\n",
    "    \n",
    "    # extract\n",
    "    step1 = soup.select('div[class*=\"im12_txt_ann\"]')\n",
    "    if len(step1)>0:\n",
    "        step2 = step1[0].select('div[class*=\"txt_annonceauto\"]')\n",
    "        if len(step2)>0:\n",
    "            raw_text = step2[0].text.split(\"Prix\")[0].strip()\n",
    "            #raw_text = unicode(raw_text, errors='replace')\n",
    "            return raw_text.replace(u'\\x80', u' ').strip().replace(\"\\n\", \" \").replace(\"\\t\", \" \")\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'pages/paruvendu-1248033282-2021-05-30_19h04.html'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-114-6257d44c5892>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mwith\u001b[0m \u001b[0mcodecs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_check_single\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'r'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'utf-8'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'ignore'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0mreadable_html\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mg_comment\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_comment\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreadable_html\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mg_comment\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.9.1/lib/python3.9/codecs.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(filename, mode, encoding, errors, buffering)\u001b[0m\n\u001b[1;32m    903\u001b[0m         \u001b[0;31m# Force opening of the file in binary mode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    904\u001b[0m         \u001b[0mmode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'b'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 905\u001b[0;31m     \u001b[0mfile\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuiltins\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuffering\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    906\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mencoding\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    907\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'pages/paruvendu-1248033282-2021-05-30_19h04.html'"
     ]
    }
   ],
   "source": [
    "with codecs.open(file_check_single, 'r', encoding='utf-8', errors='ignore') as f:\n",
    "    readable_html = f.read()\n",
    "    g_comment = get_comment(readable_html)\n",
    "g_comment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### get seller"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_seller(r):\n",
    "    \n",
    "    # get soup\n",
    "    soup = BeautifulSoup(r, 'html.parser')\n",
    "    \n",
    "    # extract\n",
    "    step1 = soup.select('p[class*=\"txtpresentation-vendeur\"]')\n",
    "    if len(step1)>0:\n",
    "        if step1[0].text.find(\"particulier\")>0:\n",
    "            return [\"Particulier\", step1[0].text.split(\":\")[-1].strip().split(\"\\n\")[0].strip()]\n",
    "        else:\n",
    "            return [\"Professionnel\", step1[0].text.strip().split(\"\\n\")[0]]\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'pages/paruvendu-1248033282-2021-05-30_19h04.html'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-116-e512a97bb320>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_check_single\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'r'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0mreadable_html\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mg_seller\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_seller\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreadable_html\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mg_seller\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'pages/paruvendu-1248033282-2021-05-30_19h04.html'"
     ]
    }
   ],
   "source": [
    "with open(file_check_single, 'r') as f:\n",
    "    readable_html = f.read()\n",
    "    g_seller = get_seller(readable_html)\n",
    "g_seller"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save image functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_images(r, uniq_id):\n",
    "    \n",
    "    # get images url list\n",
    "    image_list = []\n",
    "    \n",
    "    # get soup\n",
    "    soup_ = BeautifulSoup(r, 'html.parser')\n",
    "    \n",
    "    # extract\n",
    "    step1 = soup_.find('div',id=\"listePhotos\")\n",
    "    \n",
    "    if step1 != None:\n",
    "        if len(step1)>0:\n",
    "            step2 = step1.select(\"img\")\n",
    "            if len(step2)>0:\n",
    "                if \"src\" in step2[0].attrs:\n",
    "                    for k in range(len(step2)-1):\n",
    "                        image_list.append(step2[0].attrs[\"src\"].replace(\"_1.jpeg\", \"_\" + str(k+1) + \".jpeg\"))\n",
    "\n",
    "    # save images\n",
    "    k=1\n",
    "    for image_url in image_list[0:3]:\n",
    "        image_name = f'images/{uniq_id}-{k}.jpg'\n",
    "        if os.path.isfile(image_name) is False:\n",
    "            img_data = requests.get(image_url).content\n",
    "            with open(image_name, 'wb') as handler:\n",
    "                handler.write(img_data)\n",
    "            try:\n",
    "                image = Image.open(image_name) \n",
    "                ratio = image.size[0] / image.size[1]\n",
    "                image = image.resize((300,int(300/ratio)))\n",
    "                image.save(f'images/{uniq_id}-{k}.jpg',optimize = True, quality = 50)\n",
    "            except:\n",
    "                pass\n",
    "        k+=1\n",
    "        \n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'pages/paruvendu-1248033282-2021-05-30_19h04.html'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-122-525d2951067b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_check_single\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'r'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0mreadable_html\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mg_ref\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_reference\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreadable_html\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mget_images\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreadable_html\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mg_ref\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'pages/paruvendu-1248033282-2021-05-30_19h04.html'"
     ]
    }
   ],
   "source": [
    "with open(file_check_single, 'r') as f:\n",
    "    readable_html = f.read()\n",
    "    g_ref = get_reference(readable_html)\n",
    "    get_images(readable_html, g_ref)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"color:orangered; font-weight:700; font-size:20pt\">TEST 100 ANNONCES</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "list_test = []\n",
    "for single_ in os.listdir(\"pages\")[0:100]:\n",
    "    with open(f\"pages/{single_}\", 'r') as f:\n",
    "        readable_html = f.read()\n",
    "        g_ref = get_reference(readable_html)\n",
    "        get_images(readable_html, g_ref)\n",
    "        print(single_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 576,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#list_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract 1 announce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_announce(file_name):\n",
    "    \"\"\" this function add an announce content from paruvendu.fr to the dataframe \"\"\"\n",
    "    \n",
    "    # load csv if exists or starting from template\n",
    "    data_paruvendu = \"../../../tresboncoin/data/paruvendu.csv\"\n",
    "    #\n",
    "    if os.path.isfile(data_paruvendu) is False:\n",
    "        df = announce_template.copy()\n",
    "    else:\n",
    "        data = pd.read_csv(data_paruvendu)\n",
    "        df = announce_template.copy()\n",
    "    \n",
    "    # fill df with defined functions\n",
    "    with open(f\"annonces/{file_name}\", 'r') as f:\n",
    "        readable_html = f.read()\n",
    "        \n",
    "        df[\"url\"] = get_url(readable_html)\n",
    "        df[\"reference\"] = get_reference(readable_html)\n",
    "        df[\"unique id\"] = get_uniq_id(get_url(readable_html))\n",
    "        df[\"date_scrapped\"] = datetime.datetime.now().strftime(\"%Y/%m/%d - %Hh%M\")\n",
    "        df[\"announce_publication_date\"] = get_publication_date(readable_html)\n",
    "        df[\"vehicle brand\"] = get_brand(readable_html)\n",
    "        df[\"vehicle type\"] = get_type(readable_html)\n",
    "        df[\"moto scoot\"] = get_moto(readable_html)\n",
    "        df[\"color\"] = get_color(readable_html)\n",
    "        df[\"vehicle condition\"] = get_cond(readable_html)\n",
    "        df[\"price\"] = get_price(readable_html)\n",
    "        df[\"city\"] = get_city(readable_html)\n",
    "        df[\"postal code\"] = get_postalcode(readable_html)\n",
    "        df[\"vehicle release date\"] = get_releasedate(readable_html)\n",
    "        df[\"mileage\"] = get_mileage(readable_html)\n",
    "        df[\"Fiscal power [HP]\"] = get_power(readable_html)\n",
    "        df[\"engine capacity [CC]\"] = get_capa(readable_html)\n",
    "        df[\"comments\"] = get_comment(readable_html)\n",
    "        df[\"seller\"] = get_seller(readable_html)[0]\n",
    "        df[\"seller_name\"] = get_seller(readable_html)[1]\n",
    "    \n",
    "        # save images\n",
    "        get_images(readable_html, get_reference(readable_html))\n",
    "        \n",
    "    # concatenate to csv and write\n",
    "    try:\n",
    "        data = pd.concat([data, df], axis=0)\n",
    "        data.to_csv(path_or_buf = data_paruvendu, index=False)\n",
    "    except:\n",
    "        df.to_csv(path_or_buf = data_paruvendu, index=False)\n",
    "    \n",
    "    # deplacer le fichier html trait dans le vault\n",
    "    subprocess.run([\"mv\", f\"annonces/{file_name}\", \"vault\"])\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for single_ in os.listdir(\"annonces\"):\n",
    "    process_announce(single_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>url</th>\n",
       "      <th>reference</th>\n",
       "      <th>unique id</th>\n",
       "      <th>date_scrapped</th>\n",
       "      <th>announce_publication_date</th>\n",
       "      <th>vehicle brand</th>\n",
       "      <th>vehicle type</th>\n",
       "      <th>moto scoot</th>\n",
       "      <th>color</th>\n",
       "      <th>vehicle condition</th>\n",
       "      <th>price</th>\n",
       "      <th>city</th>\n",
       "      <th>postal code</th>\n",
       "      <th>vehicle release date</th>\n",
       "      <th>mileage</th>\n",
       "      <th>Fiscal power [HP]</th>\n",
       "      <th>engine capacity [CC]</th>\n",
       "      <th>comments</th>\n",
       "      <th>seller</th>\n",
       "      <th>seller_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1217</th>\n",
       "      <td>https://www.paruvendu.fr/a/moto-scooter/moto/y...</td>\n",
       "      <td>WV167674084</td>\n",
       "      <td>1254591302</td>\n",
       "      <td>2021/06/01 - 23h55</td>\n",
       "      <td>01/06/2021</td>\n",
       "      <td>YAMAHA</td>\n",
       "      <td>Routire</td>\n",
       "      <td>MOTO</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Meulan</td>\n",
       "      <td>78250</td>\n",
       "      <td>1982.0</td>\n",
       "      <td>70785.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>650.0</td>\n",
       "      <td>Faire offre Yamaha 650 XJ.Kilomtrage : 70 785...</td>\n",
       "      <td>Particulier</td>\n",
       "      <td>Yann M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1218</th>\n",
       "      <td>https://www.paruvendu.fr/a/moto-scooter/moto/y...</td>\n",
       "      <td>WV167540801</td>\n",
       "      <td>1254144727</td>\n",
       "      <td>2021/06/01 - 23h55</td>\n",
       "      <td>30/05/2021</td>\n",
       "      <td>YAMAHA</td>\n",
       "      <td>Routire</td>\n",
       "      <td>MOTO</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12000.0</td>\n",
       "      <td>Fontaine</td>\n",
       "      <td>38600</td>\n",
       "      <td>2015.0</td>\n",
       "      <td>38000.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>1300.0</td>\n",
       "      <td>YAMAHA, 1300 Cm3 , Routire, Essence 4 temps, ...</td>\n",
       "      <td>Particulier</td>\n",
       "      <td>Guy D</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1219</th>\n",
       "      <td>https://www.paruvendu.fr/a/moto-scooter/moto/d...</td>\n",
       "      <td>WV167690694</td>\n",
       "      <td>1254636763</td>\n",
       "      <td>2021/06/02 - 00h07</td>\n",
       "      <td>01/06/2021</td>\n",
       "      <td>DUCATI</td>\n",
       "      <td>Routire</td>\n",
       "      <td>MOTO</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9500.0</td>\n",
       "      <td>Pont--Mousson</td>\n",
       "      <td>54700</td>\n",
       "      <td>2013.0</td>\n",
       "      <td>12500.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>1200.0</td>\n",
       "      <td>DUCATI, 1200 Cm3 , Routire, Essence 4 temps, ...</td>\n",
       "      <td>Particulier</td>\n",
       "      <td>Vincent f</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    url    reference  \\\n",
       "1217  https://www.paruvendu.fr/a/moto-scooter/moto/y...  WV167674084   \n",
       "1218  https://www.paruvendu.fr/a/moto-scooter/moto/y...  WV167540801   \n",
       "1219  https://www.paruvendu.fr/a/moto-scooter/moto/d...  WV167690694   \n",
       "\n",
       "       unique id       date_scrapped announce_publication_date vehicle brand  \\\n",
       "1217  1254591302  2021/06/01 - 23h55                01/06/2021        YAMAHA   \n",
       "1218  1254144727  2021/06/01 - 23h55                30/05/2021        YAMAHA   \n",
       "1219  1254636763  2021/06/02 - 00h07                01/06/2021        DUCATI   \n",
       "\n",
       "     vehicle type moto scoot color vehicle condition    price            city  \\\n",
       "1217     Routire       MOTO   NaN               NaN      NaN          Meulan   \n",
       "1218     Routire       MOTO   NaN               NaN  12000.0        Fontaine   \n",
       "1219     Routire       MOTO   NaN               NaN   9500.0  Pont--Mousson   \n",
       "\n",
       "     postal code  vehicle release date  mileage  Fiscal power [HP]  \\\n",
       "1217       78250                1982.0  70785.0                7.0   \n",
       "1218       38600                2015.0  38000.0               12.0   \n",
       "1219       54700                2013.0  12500.0               11.0   \n",
       "\n",
       "      engine capacity [CC]                                           comments  \\\n",
       "1217                 650.0  Faire offre Yamaha 650 XJ.Kilomtrage : 70 785...   \n",
       "1218                1300.0  YAMAHA, 1300 Cm3 , Routire, Essence 4 temps, ...   \n",
       "1219                1200.0  DUCATI, 1200 Cm3 , Routire, Essence 4 temps, ...   \n",
       "\n",
       "           seller seller_name  \n",
       "1217  Particulier      Yann M  \n",
       "1218  Particulier       Guy D  \n",
       "1219  Particulier   Vincent f  "
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_paruvendu = \"../../../tresboncoin/data/paruvendu.csv\"\n",
    "data = pd.read_csv(data_paruvendu)\n",
    "data.tail(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1220, 20)"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "color                        88.442623\n",
       "vehicle condition            88.196721\n",
       "Fiscal power [HP]            20.901639\n",
       "vehicle type                 17.213115\n",
       "mileage                       2.377049\n",
       "engine capacity [CC]          2.131148\n",
       "vehicle release date          1.229508\n",
       "price                         0.655738\n",
       "comments                      0.163934\n",
       "announce_publication_date     0.163934\n",
       "city                          0.081967\n",
       "postal code                   0.081967\n",
       "seller                        0.000000\n",
       "url                           0.000000\n",
       "reference                     0.000000\n",
       "moto scoot                    0.000000\n",
       "vehicle brand                 0.000000\n",
       "date_scrapped                 0.000000\n",
       "unique id                     0.000000\n",
       "seller_name                   0.000000\n",
       "dtype: float64"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "100 * data.isnull().sum().sort_values(ascending=False)/len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://www.paruvendu.fr/a/moto-scooter/moto/ducati/1200-cm3/1254636763A1KVMOMODU'"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.iloc[-1][\"url\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1251175264 in list(data[\"unique id\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
